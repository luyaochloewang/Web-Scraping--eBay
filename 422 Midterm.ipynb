{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Design & Representation -- Luyao(Chloe) Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "Install and run SQL on your machine. Use some GUI to see / test that it runs.\n",
    "\n",
    "What data types would you chose to store (i) IP addresses (e.g., “192.168.1.1”), (ii) city names (e.g., “West Sacramento”), and (iii) ZIP codes (e.g., “95605”) in? Why?\n",
    "\n",
    "(i) IP addresses: VARCHAR IP addresses are not fixed length and are made up of numbers and special characters. (ii) City names: VARCHAR City names are made up of a series of characters and are not fixed length. (iii) Zip code: CHAR Although zip codes are made up of integers, we don’t usually treat zip codes as numbers. We cannot add or substract zip code. Zip codes in United States have a fixed length.\n",
    "Write a small program in Python or Java that (i) connects to your local SQL instance, (ii) creates the database “msba”, (iii) creates the table “ip_addresses” in “msba” containing the columns “ip”, “city”, and “zip”. This small code will create an empty table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE DATABASE IF NOT EXISTS msba\n",
      "CREATE TABLE IF NOT EXISTS msba.ip_addresses (ip VARCHAR(45),city VARCHAR(100),zip VARCHAR(10));\n"
     ]
    }
   ],
   "source": [
    "# c. create a table with with several columns\n",
    "import mysql.connector\n",
    "import warnings\n",
    "import requests\n",
    "import json\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SQL_DB = \"msba\"\n",
    "\n",
    "def main():\n",
    "    \n",
    "    SQL_TABLE_IP_ADDRESSES = \"ip_addresses\"\n",
    "    SQL_TABLE_IP_DEF = \"(\" + \\\n",
    "            \"ip VARCHAR(45)\" + \\\n",
    "            \",city VARCHAR(100)\" + \\\n",
    "            \",zip VARCHAR(10)\" + \\\n",
    "            \")\"\n",
    "    #(1)(c)  \n",
    "    create_sql_table(SQL_TABLE_IP_ADDRESSES, SQL_TABLE_IP_DEF)\n",
    "\n",
    "def create_sql_table(SQL_TABLE_IP_ADDRESSES, SQL_TABLE_IP_DEF):\n",
    "    try:\n",
    "        \n",
    "        #(1)(c)(i) connect to local SQL instance\n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                            user='root',\n",
    "                                            password='***********')\n",
    "        cursor = conn.cursor()\n",
    "        #(1)(c)(ii) create the database \"msba\"\n",
    "        query = \"CREATE DATABASE IF NOT EXISTS \" + SQL_DB\n",
    "        print(query)\n",
    "        cursor.execute(query);\n",
    "        #(1)(c)(iii) create the table \"ip_addresses\" in \"msba\" \n",
    "        query = \"CREATE TABLE IF NOT EXISTS \" + SQL_DB + \".\" + SQL_TABLE_IP_ADDRESSES + \" \" + SQL_TABLE_IP_DEF + \";\";\n",
    "        print(query)\n",
    "        cursor.execute(query);\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return\n",
    "\n",
    "    except IOError as e:\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "(a)Go to https://ipstack.com/ and make yourself familiar with the API and its use. Request a free APIKey form the page.\n",
    "(b)Specifically, please read “Specify Output Format” and “Specify Response Fields” inhttps://ipstack.com/documentation , and write down the four URL strings that return the “main” fieldsin JSON format for IP addresses “8.8.8.8”, “128.120.0.25”, “128.32.12.14”, “64.165.72.144”, and your IPaddress (use e.g. https://www.vpnmentor.com/tools/ipinfo/). \n",
    "(c)Create a program in Python or Java that executes above five API calls and prints the result to screen.:make your code pretty-print the returned JSON. You may use a package to do so.) \n",
    "(d)Parse the JSON strings in (c) to an internal Python or Java object for further handling. Then writecode that iterates through the five API requests and prints the “city” and “zip” fields to screen. \n",
    "(e)Augment your code from (d) to also write all five “ip”, “city”, and “zip” to the database you createdin (1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a. API key\n",
    "key = \"63b3c478a06f5c209d72a9fd60b730dc\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'Mountain View',\n",
      " 'continent_code': 'NA',\n",
      " 'continent_name': 'North America',\n",
      " 'country_code': 'US',\n",
      " 'country_name': 'United States',\n",
      " 'ip': '8.8.8.8',\n",
      " 'latitude': 37.38801956176758,\n",
      " 'longitude': -122.07431030273438,\n",
      " 'region_code': 'CA',\n",
      " 'region_name': 'California',\n",
      " 'type': 'ipv4',\n",
      " 'zip': '94041'}\n",
      "{'city': 'Davis',\n",
      " 'continent_code': 'NA',\n",
      " 'continent_name': 'North America',\n",
      " 'country_code': 'US',\n",
      " 'country_name': 'United States',\n",
      " 'ip': '128.120.0.25',\n",
      " 'latitude': 38.56296157836914,\n",
      " 'longitude': -121.81600952148438,\n",
      " 'region_code': 'CA',\n",
      " 'region_name': 'California',\n",
      " 'type': 'ipv4',\n",
      " 'zip': '95616'}\n",
      "{'city': 'Berkeley',\n",
      " 'continent_code': 'NA',\n",
      " 'continent_name': 'North America',\n",
      " 'country_code': 'US',\n",
      " 'country_name': 'United States',\n",
      " 'ip': '128.32.12.14',\n",
      " 'latitude': 37.87459945678711,\n",
      " 'longitude': -122.25466918945312,\n",
      " 'region_code': 'CA',\n",
      " 'region_name': 'California',\n",
      " 'type': 'ipv4',\n",
      " 'zip': '94720'}\n",
      "{'city': 'West Sacramento',\n",
      " 'continent_code': 'NA',\n",
      " 'continent_name': 'North America',\n",
      " 'country_code': 'US',\n",
      " 'country_name': 'United States',\n",
      " 'ip': '64.165.72.144',\n",
      " 'latitude': 38.57093048095703,\n",
      " 'longitude': -121.4357681274414,\n",
      " 'region_code': 'CA',\n",
      " 'region_name': 'California',\n",
      " 'type': 'ipv4',\n",
      " 'zip': '95819'}\n",
      "{'city': 'South San Francisco',\n",
      " 'continent_code': 'NA',\n",
      " 'continent_name': 'North America',\n",
      " 'country_code': 'US',\n",
      " 'country_name': 'United States',\n",
      " 'ip': '24.4.20.182',\n",
      " 'latitude': 37.65422821044922,\n",
      " 'longitude': -122.42488098144531,\n",
      " 'region_code': 'CA',\n",
      " 'region_name': 'California',\n",
      " 'type': 'ipv4',\n",
      " 'zip': '94080'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Execute API calls\n",
    "response_1 = requests.get(\"http://api.ipstack.com/8.8.8.8?access_key=63b3c478a06f5c209d72a9fd60b730dc&fields=main\").json()\n",
    "response_2 = requests.get(\"http://api.ipstack.com/128.120.0.25?access_key=63b3c478a06f5c209d72a9fd60b730dc&fields=main\").json()\n",
    "response_3 = requests.get(\"http://api.ipstack.com/128.32.12.14?access_key=63b3c478a06f5c209d72a9fd60b730dc&fields=main\").json()\n",
    "response_4 = requests.get(\"http://api.ipstack.com/64.165.72.144?access_key=63b3c478a06f5c209d72a9fd60b730dc&fields=main\").json()\n",
    "response_5 = requests.get(\"http://api.ipstack.com/24.4.20.182?access_key=63b3c478a06f5c209d72a9fd60b730dc&fields=main\").json()\n",
    "\n",
    "# Pretty-print the returned JSON\n",
    "for i in range(1,6):\n",
    "    pp.pprint(eval('response_'+str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city: Mountain View\n",
      "zip: 94041\n",
      "\n",
      "city: Davis\n",
      "zip: 95616\n",
      "\n",
      "city: Berkeley\n",
      "zip: 94720\n",
      "\n",
      "city: West Sacramento\n",
      "zip: 95819\n",
      "\n",
      "city: Brea\n",
      "zip: 92821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Create dictionary\n",
    "x1 = dict()\n",
    "\n",
    "# Parse the JSON strings to internal Python object\n",
    "# 'city', 'zip'\n",
    "for i in range(1,6):\n",
    "    x1[i] = json.loads(json.dumps(eval('response_'+str(i))), object_hook=lambda d: SimpleNamespace(**d))\n",
    "    print('city:', x1[i].city)\n",
    "    print('zip:', x1[i].zip)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('8.8.8.8', 'Mountain View', 94041)\n",
      "('73.162.100.129', 'Oakland', 94614)\n",
      "('128.32.12.14', 'Berkeley', 94720)\n",
      "('128.120.0.25', 'Davis', 95616)\n",
      "('64.165.72.144', 'West Sacramento', 95819)\n"
     ]
    }
   ],
   "source": [
    "msba = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"youpassword\",\n",
    "  database=\"msba\"\n",
    ")\n",
    "\n",
    "mycursor = msba.cursor()\n",
    "sql = \"INSERT INTO ip_addresses (ip, city, zip) VALUES (%s, %s, %s)\"\n",
    "val = [('73.162.100.129', 'Oakland', '94614'), ('8.8.8.8', 'Mountain View', '94041'), ('128.120.0.25', 'Davis', '95616'), ('128.32.12.14', 'Berkeley', '94720'), ('64.165.72.144', 'West Sacramento', '95819')\n",
    "      ]\n",
    "mycursor.executemany(sql, val)\n",
    "msba.commit()\n",
    "mycursor.execute(\"SELECT * FROM ip_addresses\")\n",
    "for x in mycursor:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 Web-scraping: President’s Day Discounts on eBay\n",
    "(a) Have a look at eBay’s President’s Day Deals page. https://www.ebay.com/e/daily-deals/hiw-presidents-day-deals-white-sale\n",
    "What is the GET request's variable name corresponding to the page number? (This section does not involve coding)\n",
    "(b) Write code that saves all non-sponsored item URLs (the URL you go to when clicking on an item) to the file \"deals.txt\" in the same directory as your code. (One URL per line)\n",
    "(c) Write a program that opens the file in (b) and downloads each of the pages (URLs) into the folders \"deals\". Each file should be named as \"<item-id>.html\" where you replace \"item-id\" with the ID of the item you are saving. E.g., \"264616053293.html\" for the item with ID \"264616053293\". Note it is always good to put a 4-second pause between queries. Make sure to catch an error and continue if your query runs into problems connecting to eBay (e.g., if your internet is down for 5 seconds, you don't want your entire code to crash).\n",
    "(d) Write a separate piece of code that loops through the pages you downloaded in (c) and opens and parses them into a Python or Java xxxxsoup-object. Identify and select: \n",
    "seller name, seller score, item price, item price, list price, # items sold, title, returns allowed (true / false), shipping price, condition (e.g., used, new, like new, seller refurbished, ...).\n",
    "In your code, highlight the selector command you choose to obtain each element using comments.\n",
    "(e) Use your code snippet from (1) to connect to SQL (either MySQL, MariaDB, or SQLite. Do NOT use SQL GUI or command terminal). Save the information of items in (d) into a single table named \"deals\" in “msba”. If an item misses ANY of the information in (d), you should insert that missing value as NULL into the table. Convert any price (item price and shipping price) into a \"dollar-cent\" format (e.g., convert $12.34 into 1234 and $12 into 1200. Make sure the two least significant digits are cents. If an item does not include cents in the price, insert zeros.) and insert the price as INT into the table. \n",
    "(f) Use your code script (and NOT SQL GUI or command terminal) to run summary stats on each item. Print to the screen the mean, min, max, and mean for each numeric column, dependent on (i) whether “list price” was providedand (ii) \"condition\" (group by at the same time, not separately). \n",
    "(g)Use the stats in (f) and tell in your own words, whether the existence of “list price” appear to influence sales. (You do NOT need to run any model or statistic calculations for this part. Make your judgment only by looking at the stats you printed in (f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.b \n",
    "import time\n",
    "headers = {'User-Agent':'Mozilla/5.0'}  \n",
    "deals_out = []\n",
    "\n",
    "#Loop through the first 10 pages \n",
    "for i in range(1,11):\n",
    "    URL= \"https://www.ebay.com/e/daily-deals/hiw-presidents-day-deals-white-sale?_pgn=\"+str(i)\n",
    "    page = requests.get(URL, headers=headers) \n",
    "    doc = BeautifulSoup(page.content, 'html.parser')\n",
    "    item_link = doc.find_all('a', class_ = 's-item__link')\n",
    "    for item in item_link:\n",
    "        item_url = item.get('href')\n",
    "        print(item_url)\n",
    "        deals_out.append(item_url)\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Write output to file 'deals.txt'\n",
    "with open(os.getcwd()+'/deals.txt', 'w+') as filehandle:\n",
    "    for item_url in deals_out:\n",
    "        filehandle.write('%s\\n' % item_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with connection...\n"
     ]
    }
   ],
   "source": [
    "# 3.c open existing file\n",
    "import os\n",
    "deals = open(os.getcwd()+'/deals.txt', 'r').read().split('\\n')\n",
    "headers = {'User-Agent':'Mozilla/5.0'}  \n",
    "\n",
    "path = os.path.join(os.getcwd() , 'deals')\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "try:\n",
    "    for URL in deals[0:216]: \n",
    "        item_id = re.search(r'.+/(\\d{12})\\?', URL).group(1)\n",
    "        page = requests.get(URL, headers=headers) \n",
    "        with open(os.path.join(path, str(item_id)+'.html'), 'w+', encoding=\"utf-8\") as filehandle:\n",
    "            filehandle.write(page.text)\n",
    "\n",
    "        #put a 2 sec pause between queries\n",
    "        time.sleep(2)\n",
    "except:\n",
    "    print('Problem with connection...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.d Access Local Files \n",
    "#initialize a data frame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "deal_info = pd.DataFrame(columns=['Seller Name', 'Seller Score', 'Item Price', 'List Price', 'Number of Items Sold',\n",
    "                                 'Title', 'Returns Allowed', 'Shipping Price', 'Condition'])\n",
    "\n",
    "for i in range(0, len(list)):\n",
    "    try:\n",
    "        page = list[i]\n",
    "        page_file = open(path + '\\\\' + page, 'r', encoding=\"utf-8\").read() \n",
    "        soup = BeautifulSoup(page_file, 'html.parser')\n",
    "\n",
    "        #selector command for seller name \n",
    "        seller_name = soup.find('div', class_ = 'mbg vi-VR-margBtm3').find('span', class_ = 'mbg-nw').get_text()\n",
    "\n",
    "        #selector command for seller score\n",
    "        seller_score = soup.find('span', class_ = 'mbg-l').find_next().get_text()\n",
    "\n",
    "        #selector command for item price\n",
    "        item_price_raw = soup.find('span', class_ = 'notranslate', itemprop = 'price').get_text()\n",
    "        item_price = round(float(re.search(r'.*\\$([\\.\\d]+)', item_price_raw).group(1)),2)\n",
    "\n",
    "        #selector command for list price (note that some items do not have list price)\n",
    "        if soup.find('span', id = 'orgPrc', class_ = 'notranslate ms-orp'):\n",
    "            list_price_raw = soup.find('span', id = 'orgPrc', class_ = 'notranslate ms-orp').get_text()\n",
    "            list_price = round(float(re.search(r'.*\\$([\\.\\d]+)', list_price_raw).group(1)),2)\n",
    "        else:\n",
    "            list_price = None #if item does not have list price, set it to null\n",
    "\n",
    "        #selector command for number of items sold (note that some items do not have # sold)\n",
    "        if soup.find('a', class_ = 'vi-txt-underline'):\n",
    "            num_sold_raw = soup.find('a', class_ = 'vi-txt-underline').get_text()\n",
    "            num_sold = re.search(r'(.+) sold', num_sold_raw).group(1)\n",
    "            num_sold = int(num_sold.replace(',',''))\n",
    "        else:\n",
    "            num_sold = 0\n",
    "\n",
    "        #selector command for title\n",
    "        title_raw = soup.find('h1', class_ = 'it-ttl', id = 'itemTitle').get_text()\n",
    "        title = title_raw.replace('Details about  \\xa0', '')\n",
    "        title\n",
    "\n",
    "        #selector command for returns allowed(true/false)\n",
    "        return_policy = soup.find('span', id = 'vi-ret-accrd-txt').get_text()\n",
    "        return_allowed = False if return_policy == 'Seller does not accept returns' else True\n",
    "\n",
    "        #selector command for shipping price\n",
    "\n",
    "        ##Note that free shipping can be standard or 'FAST N' Free'.\n",
    "        ##It's easier to check for valid shipping price. If no $ was found, then set shipping price to 0.\n",
    "        shipping_price = round(0.00,2)\n",
    "        #Check for shipping price tag\n",
    "        if soup.find('div', id = 'shippingSummary').find('span', id = 'fshippingCost'):\n",
    "            ship_pc = soup.find('div', id = 'shippingSummary').find('span', id = 'fshippingCost').find_next().get_text()\n",
    "            #See if price contains $ sign\n",
    "            if (ship_pc.find('$') != -1):\n",
    "                #if contains $, set shipping price, else set price to 0\n",
    "                shipping_price = round(float(re.search(r'.*\\$(.+)', ship_pc).group(1)),2)\n",
    "        else:\n",
    "            shipping_price = round(0.00,2)\n",
    "\n",
    "        #selector command for condition\n",
    "        condition = soup.find('div', id = 'vi-itm-cond').get_text()\n",
    "\n",
    "        #save this iteration's result to the i-th row of the dataframe\n",
    "        deal_info.loc[i] = [seller_name, seller_score, item_price, list_price, num_sold, title, \n",
    "                            return_allowed, shipping_price, condition]\n",
    "    except:\n",
    "        print('Error with: ' + page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seller Name</th>\n",
       "      <th>Seller Score</th>\n",
       "      <th>Item Price</th>\n",
       "      <th>List Price</th>\n",
       "      <th>Number of Items Sold</th>\n",
       "      <th>Title</th>\n",
       "      <th>Returns Allowed</th>\n",
       "      <th>Shipping Price</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cozyarray</td>\n",
       "      <td>219912</td>\n",
       "      <td>7.99</td>\n",
       "      <td>16.99</td>\n",
       "      <td>2791</td>\n",
       "      <td>SET OF 1500 TC PILLOWCASES TWO PILLOW CASES PE...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New with tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cozyarray</td>\n",
       "      <td>219912</td>\n",
       "      <td>7.99</td>\n",
       "      <td>17.99</td>\n",
       "      <td>14865</td>\n",
       "      <td>1200 SERIES PILLOWCASES - 2 Pillow Cases Per S...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New with tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cozyarray</td>\n",
       "      <td>219912</td>\n",
       "      <td>21.99</td>\n",
       "      <td>79.99</td>\n",
       "      <td>14504</td>\n",
       "      <td>1800 Count 4 Piece Deep Pocket Bed Sheet Set -...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New with tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cozyarray</td>\n",
       "      <td>219912</td>\n",
       "      <td>5.99</td>\n",
       "      <td>29.99</td>\n",
       "      <td>4192</td>\n",
       "      <td>Bedskirt Pins - Set of 8 Plastic Head Bed Skir...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New with tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cozyarray</td>\n",
       "      <td>219912</td>\n",
       "      <td>5.99</td>\n",
       "      <td>29.99</td>\n",
       "      <td>27877</td>\n",
       "      <td>1800 Pillow Case Set Standard or King Ultra So...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New with tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>www.powersellerusa.com</td>\n",
       "      <td>77178</td>\n",
       "      <td>14.99</td>\n",
       "      <td>23.39</td>\n",
       "      <td>406</td>\n",
       "      <td>Checked Window Curtain Drape Plaid Gingham Che...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>howplumb</td>\n",
       "      <td>146985</td>\n",
       "      <td>14.97</td>\n",
       "      <td>38.99</td>\n",
       "      <td>72</td>\n",
       "      <td>2 Blackout Window Curtains Panel Pair Grommet ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>www.powersellerusa.com</td>\n",
       "      <td>77178</td>\n",
       "      <td>12.99</td>\n",
       "      <td>75.96</td>\n",
       "      <td>189</td>\n",
       "      <td>Supreme Super Soft 4 Piece Bed Sheet Set Deep ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New with tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>dealgenius</td>\n",
       "      <td>712387</td>\n",
       "      <td>14.00</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>Blankie Tails Original Mermaid Tail Blanket Ki...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New with tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>dealgenius</td>\n",
       "      <td>712387</td>\n",
       "      <td>46.00</td>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>Berkshire Blanket 90x90 Activated Knit Full Qu...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New with tags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Seller Name Seller Score  Item Price List Price  \\\n",
       "0                 cozyarray       219912        7.99      16.99   \n",
       "1                 cozyarray       219912        7.99      17.99   \n",
       "2                 cozyarray       219912       21.99      79.99   \n",
       "3                 cozyarray       219912        5.99      29.99   \n",
       "4                 cozyarray       219912        5.99      29.99   \n",
       "..                      ...          ...         ...        ...   \n",
       "179  www.powersellerusa.com        77178       14.99      23.39   \n",
       "180                howplumb       146985       14.97      38.99   \n",
       "181  www.powersellerusa.com        77178       12.99      75.96   \n",
       "182              dealgenius       712387       14.00         25   \n",
       "183              dealgenius       712387       46.00         65   \n",
       "\n",
       "    Number of Items Sold                                              Title  \\\n",
       "0                   2791  SET OF 1500 TC PILLOWCASES TWO PILLOW CASES PE...   \n",
       "1                  14865  1200 SERIES PILLOWCASES - 2 Pillow Cases Per S...   \n",
       "2                  14504  1800 Count 4 Piece Deep Pocket Bed Sheet Set -...   \n",
       "3                   4192  Bedskirt Pins - Set of 8 Plastic Head Bed Skir...   \n",
       "4                  27877  1800 Pillow Case Set Standard or King Ultra So...   \n",
       "..                   ...                                                ...   \n",
       "179                  406  Checked Window Curtain Drape Plaid Gingham Che...   \n",
       "180                   72  2 Blackout Window Curtains Panel Pair Grommet ...   \n",
       "181                  189  Supreme Super Soft 4 Piece Bed Sheet Set Deep ...   \n",
       "182                   33  Blankie Tails Original Mermaid Tail Blanket Ki...   \n",
       "183                   13  Berkshire Blanket 90x90 Activated Knit Full Qu...   \n",
       "\n",
       "    Returns Allowed  Shipping Price      Condition  \n",
       "0              True             0.0  New with tags  \n",
       "1              True             0.0  New with tags  \n",
       "2              True             0.0  New with tags  \n",
       "3              True             0.0  New with tags  \n",
       "4              True             0.0  New with tags  \n",
       "..              ...             ...            ...  \n",
       "179            True             0.0            New  \n",
       "180            True             0.0            New  \n",
       "181            True             0.0  New with tags  \n",
       "182            True             0.0  New with tags  \n",
       "183            True             0.0  New with tags  \n",
       "\n",
       "[184 rows x 9 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created\n",
      "Row 0 successsfully inserted\n",
      "Row 1 successsfully inserted\n",
      "Row 2 successsfully inserted\n",
      "Row 3 successsfully inserted\n",
      "Row 4 successsfully inserted\n",
      "Row 5 successsfully inserted\n",
      "Row 6 successsfully inserted\n",
      "Row 7 successsfully inserted\n",
      "Row 8 successsfully inserted\n",
      "Row 9 successsfully inserted\n",
      "Row 10 successsfully inserted\n",
      "Row 11 successsfully inserted\n",
      "Row 12 successsfully inserted\n",
      "Row 13 successsfully inserted\n",
      "Row 14 successsfully inserted\n",
      "Row 15 successsfully inserted\n",
      "Row 16 successsfully inserted\n",
      "Row 17 successsfully inserted\n",
      "Row 18 successsfully inserted\n",
      "Row 19 successsfully inserted\n",
      "Row 20 successsfully inserted\n",
      "Row 21 successsfully inserted\n",
      "Row 22 successsfully inserted\n",
      "Row 23 successsfully inserted\n",
      "Row 24 successsfully inserted\n",
      "Row 25 successsfully inserted\n",
      "Row 26 successsfully inserted\n",
      "Row 27 successsfully inserted\n",
      "Row 28 successsfully inserted\n",
      "Row 29 successsfully inserted\n",
      "Row 30 successsfully inserted\n",
      "Row 31 successsfully inserted\n",
      "Row 32 successsfully inserted\n",
      "Row 33 successsfully inserted\n",
      "Row 34 successsfully inserted\n",
      "Row 35 successsfully inserted\n",
      "Row 36 successsfully inserted\n",
      "Row 37 successsfully inserted\n",
      "Row 38 successsfully inserted\n",
      "Row 39 successsfully inserted\n",
      "Row 40 successsfully inserted\n",
      "Row 41 successsfully inserted\n",
      "Row 42 successsfully inserted\n",
      "Row 43 successsfully inserted\n",
      "Row 44 successsfully inserted\n",
      "Row 45 successsfully inserted\n",
      "Row 46 successsfully inserted\n",
      "Row 47 successsfully inserted\n",
      "Row 48 successsfully inserted\n",
      "Row 49 successsfully inserted\n",
      "Row 50 successsfully inserted\n",
      "Row 51 successsfully inserted\n",
      "Row 52 successsfully inserted\n",
      "Row 53 successsfully inserted\n",
      "Row 54 successsfully inserted\n",
      "Row 55 successsfully inserted\n",
      "Row 56 successsfully inserted\n",
      "Row 57 successsfully inserted\n",
      "Row 58 successsfully inserted\n",
      "Row 59 successsfully inserted\n",
      "Row 60 successsfully inserted\n",
      "Row 61 successsfully inserted\n",
      "Row 62 successsfully inserted\n",
      "Row 63 successsfully inserted\n",
      "Row 64 successsfully inserted\n",
      "Row 65 successsfully inserted\n",
      "Row 66 successsfully inserted\n",
      "Row 67 successsfully inserted\n",
      "Row 68 successsfully inserted\n",
      "Row 69 successsfully inserted\n",
      "Row 70 successsfully inserted\n",
      "Row 71 successsfully inserted\n",
      "Row 72 successsfully inserted\n",
      "Row 73 successsfully inserted\n",
      "Row 74 successsfully inserted\n",
      "Row 75 successsfully inserted\n",
      "Row 76 successsfully inserted\n",
      "Row 77 successsfully inserted\n",
      "Row 78 successsfully inserted\n",
      "Row 79 successsfully inserted\n",
      "Row 80 successsfully inserted\n",
      "Row 81 successsfully inserted\n",
      "Row 82 successsfully inserted\n",
      "Row 83 successsfully inserted\n",
      "Row 84 successsfully inserted\n",
      "Row 85 successsfully inserted\n",
      "Row 86 successsfully inserted\n",
      "Row 87 successsfully inserted\n",
      "Row 88 successsfully inserted\n",
      "Row 89 successsfully inserted\n",
      "Row 90 successsfully inserted\n",
      "Row 91 successsfully inserted\n",
      "Row 92 successsfully inserted\n",
      "Row 93 successsfully inserted\n",
      "Row 94 successsfully inserted\n",
      "Row 95 successsfully inserted\n",
      "Row 96 successsfully inserted\n",
      "Row 97 successsfully inserted\n",
      "Row 98 successsfully inserted\n",
      "Row 99 successsfully inserted\n",
      "Row 100 successsfully inserted\n",
      "Row 101 successsfully inserted\n",
      "Row 102 successsfully inserted\n",
      "Row 103 successsfully inserted\n",
      "Row 104 successsfully inserted\n",
      "Row 105 successsfully inserted\n",
      "Row 106 successsfully inserted\n",
      "Row 107 successsfully inserted\n",
      "Row 108 successsfully inserted\n",
      "Row 109 successsfully inserted\n",
      "Row 110 successsfully inserted\n",
      "Row 111 successsfully inserted\n",
      "Row 112 successsfully inserted\n",
      "Row 113 successsfully inserted\n",
      "Row 114 successsfully inserted\n",
      "Row 115 successsfully inserted\n",
      "Row 116 successsfully inserted\n",
      "Row 117 successsfully inserted\n",
      "Row 118 successsfully inserted\n",
      "Row 119 successsfully inserted\n",
      "Row 120 successsfully inserted\n",
      "Row 121 successsfully inserted\n",
      "Row 122 successsfully inserted\n",
      "Row 123 successsfully inserted\n",
      "Row 124 successsfully inserted\n",
      "Row 125 successsfully inserted\n",
      "Row 126 successsfully inserted\n",
      "Row 127 successsfully inserted\n",
      "Row 128 successsfully inserted\n",
      "Row 129 successsfully inserted\n",
      "Row 130 successsfully inserted\n",
      "Row 131 successsfully inserted\n",
      "Row 132 successsfully inserted\n",
      "Row 133 successsfully inserted\n",
      "Row 134 successsfully inserted\n",
      "Row 135 successsfully inserted\n",
      "Row 136 successsfully inserted\n",
      "Row 137 successsfully inserted\n",
      "Row 138 successsfully inserted\n",
      "Row 139 successsfully inserted\n",
      "Row 140 successsfully inserted\n",
      "Row 141 successsfully inserted\n",
      "Row 142 successsfully inserted\n",
      "Row 143 successsfully inserted\n",
      "Row 144 successsfully inserted\n",
      "Row 145 successsfully inserted\n",
      "Row 146 successsfully inserted\n",
      "Row 147 successsfully inserted\n",
      "Row 148 successsfully inserted\n",
      "Row 149 successsfully inserted\n",
      "Row 150 successsfully inserted\n",
      "Row 151 successsfully inserted\n",
      "Row 152 successsfully inserted\n",
      "Row 153 successsfully inserted\n",
      "Row 154 successsfully inserted\n",
      "Row 155 successsfully inserted\n",
      "Row 156 successsfully inserted\n",
      "Row 157 successsfully inserted\n",
      "Row 158 successsfully inserted\n",
      "Row 159 successsfully inserted\n",
      "Row 160 successsfully inserted\n",
      "Row 161 successsfully inserted\n",
      "Row 162 successsfully inserted\n",
      "Row 163 successsfully inserted\n",
      "Row 164 successsfully inserted\n",
      "Row 165 successsfully inserted\n",
      "Row 166 successsfully inserted\n",
      "Row 167 successsfully inserted\n",
      "Row 168 successsfully inserted\n",
      "Row 169 successsfully inserted\n",
      "Row 170 successsfully inserted\n",
      "Row 171 successsfully inserted\n",
      "Row 172 successsfully inserted\n",
      "Row 173 successsfully inserted\n",
      "Row 174 successsfully inserted\n",
      "Row 175 successsfully inserted\n",
      "Row 176 successsfully inserted\n",
      "Row 177 successsfully inserted\n",
      "Row 178 successsfully inserted\n",
      "Row 179 successsfully inserted\n",
      "Row 180 successsfully inserted\n",
      "Row 181 successsfully inserted\n",
      "Row 182 successsfully inserted\n",
      "Row 183 successsfully inserted\n"
     ]
    }
   ],
   "source": [
    "# 3.e\n",
    "import mysql.connector\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SQL_DB = \"msba\"\n",
    "\n",
    "#intialize a copy of the data frame and update it with processed values during the loop \n",
    "#to prepare for summary stats in (3)(f) \n",
    "\n",
    "deal_info1 = pd.DataFrame(None, index = deal_info.index,\n",
    "                          columns=['Seller Name', 'Seller Score', 'Item Price', 'List Price', 'Number of Items Sold',\n",
    "                                 'Title', 'Returns Allowed', 'Shipping Price', 'Condition', 'Have List Price'])\n",
    "\n",
    "def main():\n",
    "    \n",
    "    SQL_TABLE_DEALS = \"deals\"\n",
    "    SQL_TABLE_DEALS_DEF = \"(\" + \\\n",
    "            \"seller_name VARCHAR(100) NULL\" + \\\n",
    "            \", seller_score INT NULL\" + \\\n",
    "            \", item_price INT NULL\" + \\\n",
    "            \", list_price INT NULL\" + \\\n",
    "            \", num_sold INT NULL\" + \\\n",
    "            \", title VARCHAR(200) NULL\" + \\\n",
    "            \", returns_allowed BOOLEAN NULL\" + \\\n",
    "            \", shipping_price INT NULL\" + \\\n",
    "            \", item_condition VARCHAR(100) NULL\" + \\\n",
    "            \")\"\n",
    "    \n",
    "    #create table \"deals\"\n",
    "    create_sql_table(SQL_TABLE_DEALS, SQL_TABLE_DEALS_DEF)\n",
    "    \n",
    "    #insert values row by row into table \"deals\", missing values will be saved as NULL\n",
    "    for i in deal_info.index:\n",
    "        try:\n",
    "            seller_name = str(deal_info['Seller Name'][i])\n",
    "        except:\n",
    "            seller_name = None\n",
    "        try:\n",
    "            seller_score = int(deal_info['Seller Score'][i])\n",
    "        except:\n",
    "            seller_score = None\n",
    "        try:\n",
    "            item_price = int(deal_info['Item Price'][i]*100)\n",
    "        except: \n",
    "            item_price = None\n",
    "        try:\n",
    "            list_price = int(deal_info['List Price'][i]*100)\n",
    "        except:\n",
    "            list_price = None\n",
    "        try:\n",
    "            num_sold = int(deal_info['Number of Items Sold'][i])\n",
    "        except:\n",
    "            num_sold = None\n",
    "        try:\n",
    "            title = str(deal_info['Title'][i])\n",
    "        except:\n",
    "            title = None\n",
    "        try:\n",
    "            returns_allowed = deal_info['Returns Allowed'][i]\n",
    "        except: \n",
    "            returns_allowed = None\n",
    "        try:\n",
    "            shipping_price = int(deal_info['Shipping Price'][i]*100)\n",
    "        except:\n",
    "            shipping_price = None\n",
    "        try:\n",
    "            item_condition = str(deal_info['Condition'][i])\n",
    "        except:\n",
    "            item_condition = None\n",
    "          \n",
    "        #update the dataframe for summary stats analysis in (3)(f)\n",
    "        deal_info1['Seller Name'][i] = seller_name\n",
    "        deal_info1['Seller Score'][i] = seller_score\n",
    "        deal_info1['Item Price'][i] = item_price\n",
    "        deal_info1['List Price'][i] = list_price\n",
    "        deal_info1['Number of Items Sold'][i] = num_sold\n",
    "        deal_info1['Title'][i] = title\n",
    "        deal_info1['Returns Allowed'][i] = returns_allowed\n",
    "        deal_info1['Shipping Price'][i] = shipping_price\n",
    "        deal_info1['Condition'][i] = item_condition\n",
    "        deal_info1['Have List Price'][i] = 0 if list_price == None else 1\n",
    "        \n",
    "        #for each iteration, insert one row into table \"deals\"\n",
    "        try:\n",
    "        \n",
    "            #connect to local SQL instance\n",
    "            conn = mysql.connector.connect(host='localhost',\n",
    "                                            user='root',\n",
    "                                            password='1234')\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            #query to insert row into table \n",
    "            entries = \"(seller_name, seller_score, item_price, list_price, num_sold, title, returns_allowed, shipping_price, item_condition)\"\n",
    "            values = (seller_name, seller_score, item_price, list_price, num_sold, title, returns_allowed, shipping_price, item_condition)        \n",
    "            query = \"INSERT INTO \" + SQL_DB + \".\" + SQL_TABLE_DEALS + \" \" + entries + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s) ;\"\n",
    "            cursor.execute(query, values)\n",
    "            conn.commit()\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            print(\"Row \" + str(i) + \" successsfully inserted\") \n",
    "        \n",
    "        except:\n",
    "            print(\"Problem with row \" + str(i))\n",
    "            \n",
    "        \n",
    "    \n",
    "# function definition for table creation sql \n",
    "def create_sql_table(SQL_TABLE_DEALS, SQL_TABLE_DEALS_DEF):\n",
    "    try:\n",
    "        \n",
    "        #connect to local SQL instance\n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                            user='root',\n",
    "                                            password='1234')\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        #create the table \"deals\" in \"msba\" \n",
    "        query = \"CREATE TABLE IF NOT EXISTS \" + SQL_DB + \".\" + SQL_TABLE_DEALS + \" \" + SQL_TABLE_DEALS_DEF + \";\";\n",
    "        print(\"Table created\")\n",
    "        cursor.execute(query);\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return\n",
    "\n",
    "    except IOError as e:\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Seller Score</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Item Price</th>\n",
       "      <th colspan=\"4\" halign=\"left\">List Price</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Number of Items Sold</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Shipping Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Have List Price</th>\n",
       "      <th>Condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>New</th>\n",
       "      <td>37965.750000</td>\n",
       "      <td>21453</td>\n",
       "      <td>20539</td>\n",
       "      <td>99658</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1049</td>\n",
       "      <td>550</td>\n",
       "      <td>3999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1977.750000</td>\n",
       "      <td>1470.5</td>\n",
       "      <td>59</td>\n",
       "      <td>6273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New with tags</th>\n",
       "      <td>60907.555556</td>\n",
       "      <td>22367</td>\n",
       "      <td>177</td>\n",
       "      <td>420348</td>\n",
       "      <td>2710.333333</td>\n",
       "      <td>2299</td>\n",
       "      <td>599</td>\n",
       "      <td>13499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1379.566667</td>\n",
       "      <td>781.5</td>\n",
       "      <td>0</td>\n",
       "      <td>6979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>New</th>\n",
       "      <td>86685.000000</td>\n",
       "      <td>77178</td>\n",
       "      <td>65499</td>\n",
       "      <td>146985</td>\n",
       "      <td>2321.272727</td>\n",
       "      <td>1499</td>\n",
       "      <td>999</td>\n",
       "      <td>9499</td>\n",
       "      <td>7703.363636</td>\n",
       "      <td>3899</td>\n",
       "      <td>2339</td>\n",
       "      <td>40595</td>\n",
       "      <td>3429.363636</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New with tags</th>\n",
       "      <td>194955.880000</td>\n",
       "      <td>219912</td>\n",
       "      <td>3197</td>\n",
       "      <td>799174</td>\n",
       "      <td>2365.533333</td>\n",
       "      <td>1998</td>\n",
       "      <td>599</td>\n",
       "      <td>7981</td>\n",
       "      <td>8007.226667</td>\n",
       "      <td>7998</td>\n",
       "      <td>1698</td>\n",
       "      <td>24999</td>\n",
       "      <td>7201.786667</td>\n",
       "      <td>629.0</td>\n",
       "      <td>0</td>\n",
       "      <td>181453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Seller Score                         \\\n",
       "                                        mean  median    min     max   \n",
       "Have List Price Condition                                             \n",
       "0               New             37965.750000   21453  20539   99658   \n",
       "                New with tags   60907.555556   22367    177  420348   \n",
       "1               New             86685.000000   77178  65499  146985   \n",
       "                New with tags  194955.880000  219912   3197  799174   \n",
       "\n",
       "                                Item Price                      List Price  \\\n",
       "                                      mean median  min    max         mean   \n",
       "Have List Price Condition                                                    \n",
       "0               New            1566.000000   1049  550   3999          NaN   \n",
       "                New with tags  2710.333333   2299  599  13499          NaN   \n",
       "1               New            2321.272727   1499  999   9499  7703.363636   \n",
       "                New with tags  2365.533333   1998  599   7981  8007.226667   \n",
       "\n",
       "                                                  Number of Items Sold  \\\n",
       "                              median   min    max                 mean   \n",
       "Have List Price Condition                                                \n",
       "0               New             <NA>  <NA>   <NA>          1977.750000   \n",
       "                New with tags   <NA>  <NA>   <NA>          1379.566667   \n",
       "1               New             3899  2339  40595          3429.363636   \n",
       "                New with tags   7998  1698  24999          7201.786667   \n",
       "\n",
       "                                                  Shipping Price             \\\n",
       "                               median min     max           mean median min   \n",
       "Have List Price Condition                                                     \n",
       "0               New            1470.5  59    6273              0      0   0   \n",
       "                New with tags   781.5   0    6979              0      0   0   \n",
       "1               New             406.0   0   28135              0      0   0   \n",
       "                New with tags   629.0   0  181453              0      0   0   \n",
       "\n",
       "                                   \n",
       "                              max  \n",
       "Have List Price Condition          \n",
       "0               New             0  \n",
       "                New with tags   0  \n",
       "1               New             0  \n",
       "                New with tags   0  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.f\n",
    "summary_df = deal_info1[['Seller Score', 'Item Price', 'List Price', 'Number of Items Sold', 'Shipping Price','Have List Price', 'Condition']]\n",
    "\n",
    "#Convert numeric columns to numeric for analysis\n",
    "convert_dict = {'Seller Score':int, 'Item Price':int,\n",
    "                'List Price':int,'Number of Items Sold':int, \n",
    "                'Shipping Price':int}\n",
    "summary_df = summary_df.convert_dtypes(convert_dict)\n",
    "\n",
    "#Summary stats \n",
    "summary_df.groupby(['Have List Price', 'Condition']).agg(['mean', 'median', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existence of ‘list price’ does appear to influence sales. From the summary stats, we can see that the median and mean item price for items with list price and items without list price are relatively close. However, the mean number of items sold for items that have list price is much higher than those without list price. We can roughly conclude that the existence of ‘list price’ appears to increase sales. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
